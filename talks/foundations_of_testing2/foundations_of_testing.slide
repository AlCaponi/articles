
Testing
Foundations of Testing - The Sequel
08:30 2 Mar 2016
Tags: testing, mspec, FluentAssert, xunit

Michael Ingold
Software Engineer, Leuchter AG
michael.ingold@leuchterag.ch
http://michaelingold.ch/
@michaelingold


* Agenda

- Review Unit Testing 1
- Faking with FakeItEasy time :-)
- Short intro to integration testing
- Exercises

* Review
What we've covered:

- Why we test...
- Different approaches to testing
- Structure of a unit testing
- Test principles (Fast, Isolated, Self-Validating, Repeatable, Timely)
- Different Abstraction Level (Unit-, Integration-, Api- and UI-Test)

* Faking

How do you test your dependencies, without killing isolation?

.code res/code/faking.cs /BEGIN1 OMIT/,/END1 OMIT/

Extract Interfaces, Fake, Inject, Test!

* Faking with FakeItEasy

.code res/code/faking.cs /BEGIN2 OMIT/,/END2 OMIT/

.caption credit to [[http://www.dotnet-zentral.ch/wp-content/uploads/2012/09/Fake-It-Easy.pdf][Philipp Dolder]]

* FakeItEasy [0]

- Basic usage:
.code res/code/FakeItEasy.cs /BEGIN1 OMIT/,/END1 OMIT/

- What: `virtual`, `abstract`, `interface`.

- Create Fakes:
.code res/code/FakeItEasy.cs /BEGIN2 OMIT/,/END2 OMIT/

* FakeItEasy [1]

- Specify return values:
.code res/code/FakeItEasy.cs /BEGIN3 OMIT/,/END3 OMIT/

- Asserting Calls:
.code res/code/FakeItEasy.cs /Assert1 OMIT/,/Assert1End OMIT/


* FakeItEasy [2]

- Argument matching:
.code res/code/FakeItEasy.cs /ARGUMENTMATCHING OMIT/,/ARGUMENTMATCHINGEND OMIT/

- Conditional argument matching:
.code res/code/FakeItEasy.cs /ARGUMENTMATCHING1 OMIT/,/ARGUMENTMATCHINGEND1 OMIT/

- Raise events:
.code res/code/FakeItEasy.cs /BEGINEVENTS OMIT/,/ENDEVENTS OMIT/

* FakeItEasy [4]

- Usage of invocation arguments:
.code res/code/FakeItEasy.cs /INVOCATIONARGS OMIT/,/INVOCATIONARGSEND OMIT/
Works with up to 4 arguments, signature is used to match (type and order)

- Usage of invocation object:
.code res/code/FakeItEasy.cs /INVOCATIONARGS1 OMIT/,/INVOCATIONARGSEND1 OMIT/
Works with arbitrary numbers of arguments, indexes must match!

*Attention*: Using invocation arguments can (and will) cause a hit on refactorability of your code!

* FakeItEasy [5]

- Throwing exceptions
.code res/code/FakeItEasy.cs /EXCEPTIONS OMIT/,/EXCEPTIONSEND OMIT/

* Integration testing

* Testing Pyramid
.image res/images/test-pyramid.png _ 700

* Integration Tests
*Scope*: Multiple units of functionality of a system.

*Execution*: should be automated.

*Goal*: Find, prevent or fix gaps in the integration of multiple units of functionality.

*Characteristics:*

- Bounded context (Does not test the world)
- Isolated (Filesystems, Databases, 3rd-party systems, etc.)
- Should be fast!
- Repeatable
- Automatically executable

* Integration Testing with `machine.specifications` [1]
- [MSpec] is an integration test framework
- Establish, Because, It, Cleanup (similar to Arrange, Act, Assert)
.code res/code/mspec.cs /SAMPLE OMIT/,/SAMPLEEND OMIT/

- Static Context (TestCases cannot run concurrently)

* Integration Testing with `machine.specifications` [2]

- [[https://github.com/machine/machine.specifications#command-line-reference][Comes with it's own test runner.]]
  $ nuget install Machine.Specifications
- Executes where the class is adorned with `[Subject(...)]`:
.code res/code/mspec.cs /ATTRIBUTES OMIT/,/ATTRIBUTESEND OMIT/
- Use Tags to run categories of test:
.code res/code/mspec.cs /TAGS OMIT/,/TAGSEND OMIT/
  $ mspec.exe --include "RegressionTest,LoadTests" <assemblies>

* Ex 1: Get an MSpec test to fail!

- Create a new Solution
- Add a new library project
- Install MSpec and the respective vs runner
  PM> Install-Package Machine.Specifications
  PM> Install-Package Machine.Specifications.Runner.VisualStudio
- create a new subject and make the test fail!
- make the test fail!

* Ex 2: Get Witschi to 100%

1. *DO NOT ASSUME A PROJECT WITH 100% CODE COVERAGE IS GOOD!!!!*
2. Checkout the Witschi solution:

  $ git clone http://sbastfsv02:8080/tfs/Individual/_git/Witschi

3. Look at the existing test `When_Requesting_Recommendation`
4. Make sure it succeeds!
5. Pick one of the following challenges.
6. Complete the challenge!
7. Win the challenge with by:

    1. Shock and awe all of us!
    2. Keep your subject as clean and simple as possible
    3. Writing sensible and concise test cases
    5. Using fancy features (i.e. extension functions, rarely used
       MSpec, FakeItEasy or FluentAssertions features, etc.)
    6. Especially clean code!

.caption Get the customers specs from the customer folder!


* Challenge 1: Complex criteria

Some criteria has to be evaluated in a more complex way that just taking the value from a dropdown box. The BMI is such a criteria. Here the value for the criterion has to be evaluated given the persons size and weight.

- Create a new subject that tests the complex criteria evaluation as implemented in `DataServiceStub.EvaluateComplexCriterion()`
- Test BMI evaluation for men and women!
- Invent your own complex criterion and add a test for that!

* Challenge 2: Data access

The frontend queries data from the backend like Pillows and Criteria. It's important this data is handled correctly and error cases are implemented to fail gracefully.

Test data access as already implemented in `DataServiceStub`:

  public IEnumerable<Pillow> GetPillows(){ .. }
  public Pillow GetPillow(string id){ .. }
  public Criterion[] GetCriteria(){ .. }
  public Criterion GetCriterion(string key){ .. }

- Test edge cases _just_as_well_ as error cases!
- Keep the `Establish` code simple and smart!

* Challenge 3: Production Data for testing

Extend the context of the `When_Requesting_Recommendation` subject to contain all original test data:

  pillows   -> $/res/bootstrap/mgo_init.js
  criteria  -> $res/bootstrap/mgo_init.js

and optionally:

  rules    -> $res/bootstrap/configurationrules.nq

- Add additional test cases for a production level pillow query!
- Keep the `Establish` code simple and smart!
